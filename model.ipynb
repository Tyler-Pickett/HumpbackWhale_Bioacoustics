{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPciQgcJJJa1LTfLWemt+4p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tyler-Pickett/HumpbackWhale_Bioacoustics/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TzhtO3JJYmr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdc85f41-ae89-4e87-a4a9-8e2f089d0871"
      },
      "source": [
        "!pip install librosa\n",
        "import librosa\n",
        "import librosa.display\n",
        "import soundfile as sf\n",
        "\n",
        "import os\n",
        "import pathlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from IPython import display as ipd\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import keras\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from keras import layers\n",
        "from keras.layers import Activation, Dense, Dropout, Conv2D, Flatten, MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling1D, AveragePooling2D, Input, Add\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import SGD\n",
        "# Set seed for experiment reproducibility\n",
        "seed = 42\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.19.5)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.22.2.post1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.0)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (2.4.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YuGF5KiiJcN"
      },
      "source": [
        "The command to convert the flac format to x.wav is:\n",
        "flac -df --delete-input-file --preserve-modtime --keep-foreign-metadata <path to file>\n",
        " - for NOAA humpbackwhale1 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bajPkd6pmRNe",
        "outputId": "2dcc6832-2616-4780-f161-ff805ff70168"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrGMQ2xgmZt7"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UQStxZlmdA1"
      },
      "source": [
        "from google.cloud import storage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szeq2kfWBTyK"
      },
      "source": [
        "audio = '/content/drive/MyDrive/Colab Notebooks/capstone/Cross_02_060203_071428.d20_7.wav'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3G14sU258YQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e78bcf7b-ca73-4632-b8ee-a0117891e915"
      },
      "source": [
        "yamnet_model = hub.load('https://tfhub.dev/google/yamnet/1')\n",
        "yamnet_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject at 0x7f532299b1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLgt7CU2GVdK"
      },
      "source": [
        "The model classifies 3.92-second context windows of audio as containing or not containing humpback whale sounds. It is intended to be applied as a detector by scoring every context window in a set of underwater passive acoustic monitoring data.\n",
        "\n",
        "The model feeds a PCEN-normalized spectrogram through a ResNet-50 architecture to a single logistic output unit.\n",
        "\n",
        "https://tfhub.dev/google/humpback_whale/1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDHFK8jfGkwA"
      },
      "source": [
        "Inputs\n",
        "\n",
        "    waveform, a float32 Tensor of shape [batch_size, num_samples, num_channels], where it is required that num_channels = 1, but where batch_size and num_samples may take the caller's preferred values on each call.\n",
        "        Each audio channel (slice [channel_index, :, 0]), should contain 10kHz PCM float32 audio.\n",
        "            The training data left plenty of headroom; the level of clips with humpback present was typically 0.003 RMS, 0.02 peak, much \"quieter\" than consumer digital audio.\n",
        "            Although the model is relatively insensitive to input gain variations as wide as +/-20 dB, users may wish to apply linear scaling to match the levels the model saw in training.\n",
        "    context_samples, an int64 Tensor of shape [], the hop length at which to slide the scoring context window over waveform.\n",
        "\n",
        "Advanced Usage\n",
        "\n",
        "Model attributes allow isolated reuse of parts of the model, in accord with the Reusable SavedModels interface. The callable attributes exposed are:\n",
        "\n",
        "    front_end, which can be called on a waveform Tensor as described in the score signature inputs to produce a PCEN-normalized spectrogram of shape [batch_size, num_stft_bins, num_channels], where num_channels = 64 is fixed and where num_stft_bins depends on the number of input samples.\n",
        "    features, which when called on a PCEN spectrogram slice of shape [batch_size, 128, 64] produces feature vectors of shape [batch_size, 2048]. (These might be useful for detecting other audio event types in the HARP data or similar underwater passive acoustic monitoring datasets, but the model developers have not yet validated this through experiment.)\n",
        "    logits, which, when called on the same type of input as features, outputs the log odds of the input spectrogram containing humpback vocalization.\n",
        "\n",
        "https://tfhub.dev/google/humpback_whale/1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OmDjywX6LbT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbc82b5a-019e-40d3-d9e7-999f7d91c1b4"
      },
      "source": [
        "noaa_model = hub.load('https://tfhub.dev/google/humpback_whale/1')\n",
        "\n",
        "waveform, _ = tf.audio.decode_wav(tf.io.read_file(audio))\n",
        "waveform = tf.expand_dims(waveform, 0)  # makes a batch of size 1\n",
        "\n",
        "pcen_spectrogram = noaa_model.front_end(waveform)\n",
        "context_window = pcen_spectrogram[:, :128, :]\n",
        "features = noaa_model.features(context_window)\n",
        "logits = noaa_model.logits(context_window)\n",
        "probabilities = tf.nn.sigmoid(logits)\n",
        "\n",
        "print({\n",
        "    'pcen_spectrogram': pcen_spectrogram,\n",
        "    'features': features,\n",
        "    'logits': logits,\n",
        "    'probabilities': probabilities,\n",
        "})\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'pcen_spectrogram': <tf.Tensor: shape=(1, 2497, 64), dtype=float32, numpy=\n",
            "array([[[0.34337044, 0.352898  , 0.3364389 , ..., 0.31550467,\n",
            "         0.30421436, 0.3076837 ],\n",
            "        [0.01286328, 0.11843181, 0.3996929 , ..., 0.36540306,\n",
            "         0.38193512, 0.3762561 ],\n",
            "        [0.02342975, 0.06558275, 0.18811762, ..., 0.48939407,\n",
            "         0.4787593 , 0.2955898 ],\n",
            "        ...,\n",
            "        [0.14307153, 0.22290611, 0.5149369 , ..., 0.1615628 ,\n",
            "         0.2538408 , 0.39627314],\n",
            "        [0.13941622, 0.06648052, 0.13821816, ..., 0.22090185,\n",
            "         0.3079667 , 0.3320781 ],\n",
            "        [0.1844101 , 0.17328954, 0.07394493, ..., 0.21915352,\n",
            "         0.30805433, 0.1828376 ]]], dtype=float32)>, 'features': <tf.Tensor: shape=(1, 2048), dtype=float32, numpy=\n",
            "array([[1.6633583 , 0.77532035, 1.2360727 , ..., 2.1375327 , 1.1309146 ,\n",
            "        2.7635047 ]], dtype=float32)>, 'logits': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[2.268429]], dtype=float32)>, 'probabilities': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.9062284]], dtype=float32)>}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40UejO6WHDXG"
      },
      "source": [
        "Outputs\n",
        "\n",
        "    scores, a float32 Tensor of shape [batch_size, num_windows, num_classes], where it will always be true that num_classes = 1, where batch_size will equal the one from the input, and where num_windows is determined by num_samples and context_step_samples.\n",
        "\n",
        "https://tfhub.dev/google/humpback_whale/1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MokKFxiep0Lc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e46b3c75-bcff-4bc9-f9cd-294f55244626"
      },
      "source": [
        "metadata_fn = noaa_model.signatures['metadata']\n",
        "metadata = metadata_fn()\n",
        "print(metadata)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'class_names': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Mn'], dtype=object)>, 'input_sample_rate': <tf.Tensor: shape=(), dtype=int64, numpy=10000>, 'context_width_samples': <tf.Tensor: shape=(), dtype=int64, numpy=39124>}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tngX-VR7HLGl"
      },
      "source": [
        "Acknowledgements\n",
        "\n",
        "The model developers thank NOAA Pacific Islands Fisheries Science Center for collecting and sharing the data and for their partnership in the model development process, which included providing the initial training labels as well as labels for several rounds of active learning that improved candidate models.\n",
        "\n",
        "Regarding the dataset, please also refer to the funding and acknowledgement sections in Allen et al."
      ]
    }
  ]
}